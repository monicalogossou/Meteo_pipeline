# ğŸŒ¦ï¸ Projet Pipeline de DonnÃ©es MÃ©tÃ©o et Visualisation

## ğŸ“Œ Contexte & Objectif

Ce projet a pour but de construire un pipeline de donnÃ©es automatisÃ© pour :

- Collecter quotidiennement les donnÃ©es mÃ©tÃ©o de 12 pays via une API publique.
- Stocker ces donnÃ©es au format brut (`JSON`) puis transformÃ© (`Parquet`).
- Charger les donnÃ©es transformÃ©es dans une base PostgreSQL.
- Visualiser les donnÃ©es dans un outil BI (Power BI).

---

## ğŸ› ï¸ Stack Technique

| Composant       | RÃ´le                                              |
|-----------------|---------------------------------------------------|
| **Python**      | Scripts dâ€™extraction depuis lâ€™API                 |
| **Apache Airflow** | Orchestration des tÃ¢ches                        |
| **Apache Spark** | Transformation et nettoyage des donnÃ©es          |
| **PostgreSQL**  | Stockage des donnÃ©es structurÃ©es                  |
| **Docker Compose** | Conteneurisation et orchestration des services |
| **Power BI**    | Analyse et visualisation des donnÃ©es              |

---

## ğŸ“ Architecture & Outils UtilisÃ©s


![Structure](image/structure.png)
---

## ğŸ”„ Pipeline de Traitement

**Extraction**  
- Script Python (`fetch_weather.py`) appelle lâ€™API mÃ©tÃ©o avec 12 pays ciblÃ©s.  
- Les fichiers JSON sont stockÃ©s dans `data/raw/`.

**Transformation**  
- Spark transforme les donnÃ©es : nettoyage, typage, mise au format.  
- Sauvegarde en fichiers `Parquet` dans `data/processed/`.

**Chargement**  
- Spark charge les donnÃ©es dans une base PostgreSQL via JDBC.

**Orchestration**  
- Airflow automatise le pipeline avec un DAG : extraction â†’ transformation â†’ chargement.

**Visualisation (Ã  venir)**  
- Connexion Power BI Ã  la base PostgreSQL pour crÃ©er des dashboards mÃ©tÃ©o.

---

## âœ… Ce qui fonctionne

- âœ… Extraction automatisÃ©e via Airflow.  
- âœ… Stockage des fichiers bruts (JSON).  
- âœ… Transformation des donnÃ©es avec Spark.  
- âœ… Chargement dans PostgreSQL.  
- âœ… Pipeline DockerisÃ© & modulaire.

---

## ğŸ“ˆ Prochaines Ã©tapes

- ğŸ” IntÃ©gration de Power BI pour la visualisation des donnÃ©es mÃ©tÃ©o.  
- ğŸ§© Mise en place de tests unitaires pour les scripts Spark et Python.  
- ğŸ“Š Ajout de statistiques exploratoires dans PostgreSQL.  
- ğŸ“ˆ Suivi d'exÃ©cution (monitoring) du pipeline.

---

## ğŸ“· Diagramme d'architecture



![Architecture du pipeline](image/Architecture.png)
